<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>GenAI in Academia - Generative AI Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="mermaid-theme" content="neutral">
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">


</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../fundamentals/01_ecosystem.html">Fundamentals of GenAI</a></li><li class="breadcrumb-item"><a href="../fundamentals/02_models.html">Models</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">GenAI in Academia</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Fundamentals of GenAI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fundamentals/01_ecosystem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Ecosystem</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fundamentals/02_models.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fundamentals/03_agents.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Agents</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fundamentals/04_interfaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interfaces</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Resources</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#what-happens-when-you-prompt" id="toc-what-happens-when-you-prompt" class="nav-link active" data-scroll-target="#what-happens-when-you-prompt"><span class="header-section-number">1</span> What Happens When You Prompt</a></li>
  <li><a href="#what-is-an-llm" id="toc-what-is-an-llm" class="nav-link" data-scroll-target="#what-is-an-llm"><span class="header-section-number">2</span> What is an LLM?</a>
  <ul class="collapse">
  <li><a href="#how-the-numbers-are-obtained" id="toc-how-the-numbers-are-obtained" class="nav-link" data-scroll-target="#how-the-numbers-are-obtained"><span class="header-section-number">2.1</span> How the Numbers Are Obtained</a></li>
  </ul></li>
  <li><a href="#the-context-window" id="toc-the-context-window" class="nav-link" data-scroll-target="#the-context-window"><span class="header-section-number">3</span> The Context Window</a>
  <ul class="collapse">
  <li><a href="#what-providers-may-automatically-include-in-the-context-window-even-if-you-dont-see-it" id="toc-what-providers-may-automatically-include-in-the-context-window-even-if-you-dont-see-it" class="nav-link" data-scroll-target="#what-providers-may-automatically-include-in-the-context-window-even-if-you-dont-see-it"><span class="header-section-number">3.1</span> What providers may automatically include in the context window (even if you don’t see it)</a></li>
  <li><a href="#uploading-files-with-your-prompt" id="toc-uploading-files-with-your-prompt" class="nav-link" data-scroll-target="#uploading-files-with-your-prompt"><span class="header-section-number">3.2</span> Uploading files with your prompt</a></li>
  <li><a href="#what-happens-when-you-near-the-limit-of-the-context-window" id="toc-what-happens-when-you-near-the-limit-of-the-context-window" class="nav-link" data-scroll-target="#what-happens-when-you-near-the-limit-of-the-context-window"><span class="header-section-number">3.3</span> What happens when you near the limit of the context window</a></li>
  <li><a href="#output-limits" id="toc-output-limits" class="nav-link" data-scroll-target="#output-limits"><span class="header-section-number">3.4</span> Output limits</a></li>
  </ul></li>
  <li><a href="#frontier-genai-models-are-multimodal" id="toc-frontier-genai-models-are-multimodal" class="nav-link" data-scroll-target="#frontier-genai-models-are-multimodal"><span class="header-section-number">4</span> Frontier GenAI Models are Multimodal</a></li>
  <li><a href="#main-shortcomings" id="toc-main-shortcomings" class="nav-link" data-scroll-target="#main-shortcomings"><span class="header-section-number">5</span> Main Shortcomings</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Generative AI Models</h1>
<p class="subtitle lead">A non-technical introduction to GenAI models, their capabilities, and their shortcomings</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="what-happens-when-you-prompt" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="what-happens-when-you-prompt"><span class="header-section-number">1</span> What Happens When You Prompt</h2>
<p>When you type a question into ChatGPT or Claude, here’s what actually happens:</p>
<ol type="1">
<li><p><strong>Tokenization:</strong> Your prompt is converted into a sequence of numbers. Text is split into “tokens”—not exactly words, but chunks. Common words are single tokens; rare words get split into pieces. Each token maps to a number (ID) the model can process. Each model has its own vocabulary of tokens.</p></li>
<li><p><strong>Context assembly:</strong> Your prompt is combined with any previous messages in the conversation, plus a “system prompt” (instructions the model provider includes automatically).</p>
<ul>
<li><strong>Context Window</strong>: The model sees all tokens in the context at once (no memory between subsequent prompts). Window size limits how much text fits in a single interaction. Larger windows = more capability but higher cost.</li>
</ul></li>
<li><p><strong>Forward pass:</strong> The tokenized input goes through the model’s neural network. Each layer does mathematical operations—essentially matrix multiplications—transforming the input through the billions of parameters.</p></li>
<li><p><strong>Output generation:</strong> The model produces a probability distribution over all possible next tokens in its vocabulary. It samples from this distribution (with some randomness controlled by “temperature”), adds that token to the sequence, and repeats until it ends up sampling a “stop” token.</p>
<ul>
<li><strong>Temperature</strong>: Controls randomness in selection:
<ul>
<li>Temperature = 0: Always pick the highest-probability token (deterministic)</li>
<li>Temperature = 1: Sample proportionally to probabilities<br>
</li>
<li>Temperature &gt; 1: Flatten the distribution (more random/creative)</li>
</ul></li>
</ul></li>
<li><p><strong>Detokenization:</strong> Once a “stop” token is reached, the output tokens are converted back to human-readable text.</p></li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    subgraph Input
        A["User Prompt"]
        S["System Prompt"]
    end
    
    subgraph Tokenization
        B["Tokenizer"]
        C["Token IDs"]
    end
    
    subgraph Processing
        D["Context Window"]
        E["LLM"]
    end
    
    subgraph Output
        F{"Probability\nDistribution"}
        G["Temperature"]
        H["Selected Token"]
    end
    
    A --&gt; B
    S --&gt; B
    B --&gt; C --&gt; D --&gt; E --&gt; F --&gt; G --&gt; H
    H --&gt;|"Append &amp; repeat"| D
    linkStyle 8 stroke-dasharray: 5 5
</pre>
</div>
</div>
</div>
</div>
</section>
<section id="what-is-an-llm" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="what-is-an-llm"><span class="header-section-number">2</span> What is an LLM?</h2>
<p><strong>A large language model is just a file full of numbers.</strong></p>
<p>When companies like OpenAI, Anthropic, or Google train a model, they’re creating a very large file—hundreds of gigabytes for frontier models—that contains billions of numerical parameters. These parameters encode patterns learned from reading enormous amounts of text.</p>
<p>That is what the model “knows”—statistical patterns about how language works and what tends to follow what.</p>
<section id="how-the-numbers-are-obtained" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="how-the-numbers-are-obtained"><span class="header-section-number">2.1</span> How the Numbers Are Obtained</h3>
<p>The training process happens in stages:</p>
<p><strong>Pre-training:</strong> The model reads massive amounts of text from the internet, books, code repositories, academic papers—essentially a substantial portion of human written output. During this phase, it learns to predict “what word comes next?” billions of times. The parameters adjust to get better at prediction. This takes months and costs tens to hundreds of millions of dollars in compute.</p>
<p><strong>Post-training (Fine-tuning):</strong> The base model is then adjusted using:</p>
<ul>
<li><strong>Supervised fine-tuning (SFT):</strong> Humans write example conversations showing how the model should respond</li>
<li><strong>Reinforcement learning from human feedback (RLHF):</strong> Humans rate model outputs, and the model learns to generate outputs that get higher ratings</li>
<li><strong>Constitutional AI (CAI):</strong> Used by Anthropic, where the model learns to critique and revise its own outputs based on principles</li>
</ul>
<p><strong>Continuous refinement:</strong> Models are updated regularly to improve performance, fix issues, and add capabilities.</p>
<p>Key terms you might hear: “transformer architecture” (the mathematical structure these models use), “attention mechanism” (how the model decides what parts of the input to focus on), “parameters” or “weights” (the numbers in the file).</p>
<hr>
</section>
</section>
<section id="the-context-window" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="the-context-window"><span class="header-section-number">3</span> The Context Window</h2>
<p>The context window is the maximum amount of text (and other inputs) the model can consider at once:<br>
<strong>(system instructions + your prompt + chat history + retrieved snippets + tool outputs + file excerpts) + the model’s output.</strong></p>
<p>If the total exceeds the limit:</p>
<ul>
<li>the system must drop, summarize, or “compact” something,</li>
<li>or it returns an error (depending on provider).</li>
</ul>
<section id="what-providers-may-automatically-include-in-the-context-window-even-if-you-dont-see-it" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="what-providers-may-automatically-include-in-the-context-window-even-if-you-dont-see-it"><span class="header-section-number">3.1</span> What providers may automatically include in the context window (even if you don’t see it)</h3>
<p>Many modern assistants can add extra context such as:</p>
<ul>
<li>system safety instructions,</li>
<li>your custom instructions,</li>
<li>project instructions,</li>
<li>“memory” items (facts it saved about your preferences),</li>
<li>snippets retrieved from uploaded files or connected tools.</li>
</ul>
<p>This is why two people can ask the “same prompt” and get slightly different results.</p>
</section>
<section id="uploading-files-with-your-prompt" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="uploading-files-with-your-prompt"><span class="header-section-number">3.2</span> Uploading files with your prompt</h3>
<p>In most systems, uploading a file does <strong>not</strong> mean the entire file is placed into the context window verbatim.</p>
<p>A common approach is <strong>retrieval</strong>:</p>
<ul>
<li>the file is chunked,</li>
<li>the system builds embeddings (a searchable representation) from each chunk</li>
<li>and only relevant chunks are pulled into the context window when needed (based on what you asked about the file)</li>
</ul>
</section>
<section id="what-happens-when-you-near-the-limit-of-the-context-window" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="what-happens-when-you-near-the-limit-of-the-context-window"><span class="header-section-number">3.3</span> What happens when you near the limit of the context window</h3>
<p>Different providers handle this differently:</p>
<ul>
<li>Some UIs summarize older messages.</li>
<li>Some drop the earliest conversation turns (“truncation”).</li>
<li>Some run a compaction step to preserve key details.</li>
</ul>
</section>
<section id="output-limits" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="output-limits"><span class="header-section-number">3.4</span> Output limits</h3>
<p>Even with a very large <strong>input</strong> window, models have <strong>output caps</strong>. When you ask for “write 30 pages,” you usually get:</p>
<ul>
<li>a truncated response,</li>
<li>or a refusal,</li>
<li>or “here is an outline; ask me to expand section by section.”</li>
</ul>
<p><strong>Recommendation:</strong><br>
For long outputs, ask the model to 1) write an outline, 2) draft section 1, 3) draft section 2…<br>
This yields better control and fewer errors.</p>
</section>
</section>
<section id="frontier-genai-models-are-multimodal" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="frontier-genai-models-are-multimodal"><span class="header-section-number">4</span> Frontier GenAI Models are Multimodal</h2>
<p>Models like GPT 5.2 and Gemini 3.0 are multimodal: they can input and output text, audio, images, and videos.</p>
<p>TODO:</p>
<ul>
<li>explain that they still input and output tokens (just with a different representation)</li>
<li>mention names of specialized models like Nano Banana Pro, and Sora (anything for speach?) and how they are integrated with the main models (GPT 5.2, Gemini 3.0 etc.)</li>
</ul>
</section>
<section id="main-shortcomings" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="main-shortcomings"><span class="header-section-number">5</span> Main Shortcomings</h2>
<ul>
<li>Long-term memory (context window is short-term memory)</li>
<li>Halucinations</li>
<li>Inability to act (exert change on external systems)</li>
</ul>
<p>The “Agents” pages describes modern advances in addressing these shortcomings.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">GenAI For Teaching and Research | 2026</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>