[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "DeepLearning.AI — Generative AI for Everyone — Excellent intro course by Andrew Ng\nGoogle — Generative AI Learning Path — Comprehensive Google Cloud training\nPrompt Engineering Guide — Community resource for prompting techniques\n\n\n\n\n\n\n\nProvider\nDocumentation\n\n\n\n\nOpenAI\nplatform.openai.com/docs\n\n\nAnthropic\ndocs.anthropic.com\n\n\nGoogle\nai.google.dev\n\n\n\n\n\n\n\nCo-Intelligence by Ethan Mollick — Practical guide to working with AI\nThe Alignment Problem by Brian Christian — Understanding AI safety\nAI 2041 by Kai-Fu Lee & Chen Qiufan — Future scenarios"
  },
  {
    "objectID": "resources.html#learning-resources",
    "href": "resources.html#learning-resources",
    "title": "Resources",
    "section": "",
    "text": "DeepLearning.AI — Generative AI for Everyone — Excellent intro course by Andrew Ng\nGoogle — Generative AI Learning Path — Comprehensive Google Cloud training\nPrompt Engineering Guide — Community resource for prompting techniques\n\n\n\n\n\n\n\nProvider\nDocumentation\n\n\n\n\nOpenAI\nplatform.openai.com/docs\n\n\nAnthropic\ndocs.anthropic.com\n\n\nGoogle\nai.google.dev\n\n\n\n\n\n\n\nCo-Intelligence by Ethan Mollick — Practical guide to working with AI\nThe Alignment Problem by Brian Christian — Understanding AI safety\nAI 2041 by Kai-Fu Lee & Chen Qiufan — Future scenarios"
  },
  {
    "objectID": "resources.html#tools-platforms",
    "href": "resources.html#tools-platforms",
    "title": "Resources",
    "section": "2 Tools & Platforms",
    "text": "2 Tools & Platforms\n\n2.1 Conversational AI\n\nChatGPT — OpenAI’s flagship interface\nClaude — Anthropic’s assistant\nGemini — Google’s AI assistant\nPerplexity — AI-powered search\n\n\n\n2.2 Development Tools\n\nGitHub Copilot — AI pair programmer\nCursor — AI-first code editor\nReplit — AI-assisted coding platform\n\n\n\n2.3 Image Generation\n\nMidjourney — High-quality image generation\nDALL-E — OpenAI’s image model\nStable Diffusion — Open-source image generation"
  },
  {
    "objectID": "resources.html#research-news",
    "href": "resources.html#research-news",
    "title": "Resources",
    "section": "3 Research & News",
    "text": "3 Research & News\n\n3.1 Stay Updated\n\nThe Batch — Weekly AI newsletter by DeepLearning.AI\nImport AI — Weekly AI developments newsletter\nAI News — Daily AI news digest\n\n\n\n3.2 Research\n\narXiv AI — Latest AI research papers\nPapers With Code — Research with implementations\nHugging Face — Models, datasets, and community"
  },
  {
    "objectID": "resources.html#community",
    "href": "resources.html#community",
    "title": "Resources",
    "section": "4 Community",
    "text": "4 Community\n\n4.1 Forums & Discussion\n\nr/MachineLearning — Research-focused community\nr/LocalLLaMA — Open-source LLM community\nHacker News — Tech community with AI coverage\n\n\n\n4.2 Professional Networks\n\nAI LinkedIn Groups — Professional AI communities\nLocal AI Meetups — In-person events"
  },
  {
    "objectID": "resources.html#prompt-libraries",
    "href": "resources.html#prompt-libraries",
    "title": "Resources",
    "section": "5 Prompt Libraries",
    "text": "5 Prompt Libraries\n\n\n\n\n\n\nUseful Prompt Collections\n\n\n\n\nAwesome ChatGPT Prompts\nFlowGPT — Community prompts\nPromptBase — Prompt marketplace"
  },
  {
    "objectID": "resources.html#ethics-safety",
    "href": "resources.html#ethics-safety",
    "title": "Resources",
    "section": "6 Ethics & Safety",
    "text": "6 Ethics & Safety\n\n6.1 Guidelines & Frameworks\n\nNIST AI Risk Management Framework\nEU AI Act Overview\nResponsible AI Practices\n\n\n\n6.2 Critical Perspectives\n\nAI Incident Database — Documented AI failures\nAlgorithm Watch — Critical AI analysis\n\n\nThis resource list is regularly updated. Have a suggestion? Let us know!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GenAI for Teaching and Research",
    "section": "",
    "text": "This website is designed to provide an introduction to Generative AI (GenAI) technologies, with a focus on practical understanding and effective utilization of these tools for teaching and research. The goal of the website is to provide a repository of resources that academics can use to:\n\nUnderstand the fundamental concepts behind generative AI and large language models\nNavigate the current landscape of GenAI tools and platforms\nIdentify key capabilities and limitations of different GenAI systems\nSelect appropriate tools for various use cases\nApply best practices for effective GenAI utilization"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "GenAI for Teaching and Research",
    "section": "",
    "text": "This website is designed to provide an introduction to Generative AI (GenAI) technologies, with a focus on practical understanding and effective utilization of these tools for teaching and research. The goal of the website is to provide a repository of resources that academics can use to:\n\nUnderstand the fundamental concepts behind generative AI and large language models\nNavigate the current landscape of GenAI tools and platforms\nIdentify key capabilities and limitations of different GenAI systems\nSelect appropriate tools for various use cases\nApply best practices for effective GenAI utilization"
  },
  {
    "objectID": "index.html#safety-and-privacy",
    "href": "index.html#safety-and-privacy",
    "title": "GenAI for Teaching and Research",
    "section": "2 Safety and privacy",
    "text": "2 Safety and privacy\nBefore we talk about capabilities, we need shared norms. The biggest risks of GenAI in education and research are not “the models are too powerful,” but rather misplaced trust and unsafe data handling.\n\nDon’t upload sensitive data into consumer tools unless your institution has an approved, protected environment (“Enterprise” level subscriptions usually offer this).\n\nExamples of sensitive data: identifiable student info (FERPA), unpublished manuscripts, reviewer comments, proprietary datasets, IRB-protected data, confidential employer partner data.\n\nVerification is a skill, not an afterthought.\n\nTreat the model like a smart research/teaching assistant: helpful, fast, and occasionally wrong.\n\nWe will not debate whether students “should” use AI. They already are. The more productive conversation revolves around questions like:\n\nWhat learning outcomes do we want, in a world where GenAI can perform many of the tasks we traditionally teach our students?\nHow do we design assessments that reward thinking/understanding?"
  },
  {
    "objectID": "fundamentals/key-capabilities.html",
    "href": "fundamentals/key-capabilities.html",
    "title": "Key GenAI Capabilities",
    "section": "",
    "text": "Bigger windows help with long syllabi, papers, transcripts, cases, and multi-file projects.\nBut bigger windows do not guarantee accurate long-document reasoning.\n\nExamples of publicly stated context sizes (as of late 2025):\n\nOpenAI’s GPT‑5.2 Pro API model: 400k context window, 128k max output (API docs).[^openai-gpt52pro-api]\n\nChatGPT UI (GPT‑5.2): context varies by tier/model (e.g., “Thinking” has a much larger window than “Instant”).[^openai-gpt52-chatgpt]\n\nGoogle Gemini 2.5 Pro: announced 1M token context.[^google-gemini-25pro]\n\nAnthropic Claude long-context tiers include models with up to 1M tokens.[^anthropic-context]\n\n\n\n\nAsk:\n\nCan it read charts, tables, and screenshots?\nCan it generate images or just analyze them?\nIs multimodality native (one model) or stitched (separate encoders + LLM)?\n\nFor finance, multimodality matters for:\n\nreading charts in papers,\ninterpreting slide decks,\nextracting data from PDFs and tables,\nunderstanding UI screenshots from trading or analytics tools.\n\n\n\n\nMany providers now offer a mode that:\n\nspends more compute to deliberate,\nperforms better on multi-step tasks,\nis slower and more expensive.\n\nOpenAI’s GPT‑5.2 “Auto” can switch between Instant and Thinking; the UI can show a “slimmed-down” view of chain-of-thought, with an “Answer now” option.[^openai-gpt52-chatgpt]\n\n\n\nA model with tool access can:\n\nbrowse the web (and cite sources),\nuse a Python environment for calculations,\nanalyze files,\ngenerate spreadsheets / slide decks,\ncall external tools through connectors or “actions.”\n\nWithout tools, models are limited to:\n\ntheir training data,\nand whatever you provide in the prompt.\n\n\n\n\n“Deep research” typically means an agentic workflow:\n\nit searches,\ncollects sources,\nsynthesizes,\nand returns citations and an organized report.[^openai-deep-research]\n\nThis is usually not a separate “brain”; it’s an agent layer on top of a strong model + tools.\n\n\n\nCoding assistants aren’t only for programmers. Even if you don’t write software, they can:\n\ntranslate between Stata/R/Python,\nwrite reproducible scripts,\ngenerate data cleaning code,\nand explain unfamiliar code you inherited.\n\nOpenAI’s Codex ecosystem is one example (web/CLI/IDE integrations).[^openai-codex]"
  },
  {
    "objectID": "fundamentals/key-capabilities.html#key-ways-models-differ-what-to-pay-attention-to",
    "href": "fundamentals/key-capabilities.html#key-ways-models-differ-what-to-pay-attention-to",
    "title": "Key GenAI Capabilities",
    "section": "",
    "text": "Bigger windows help with long syllabi, papers, transcripts, cases, and multi-file projects.\nBut bigger windows do not guarantee accurate long-document reasoning.\n\nExamples of publicly stated context sizes (as of late 2025):\n\nOpenAI’s GPT‑5.2 Pro API model: 400k context window, 128k max output (API docs).[^openai-gpt52pro-api]\n\nChatGPT UI (GPT‑5.2): context varies by tier/model (e.g., “Thinking” has a much larger window than “Instant”).[^openai-gpt52-chatgpt]\n\nGoogle Gemini 2.5 Pro: announced 1M token context.[^google-gemini-25pro]\n\nAnthropic Claude long-context tiers include models with up to 1M tokens.[^anthropic-context]\n\n\n\n\nAsk:\n\nCan it read charts, tables, and screenshots?\nCan it generate images or just analyze them?\nIs multimodality native (one model) or stitched (separate encoders + LLM)?\n\nFor finance, multimodality matters for:\n\nreading charts in papers,\ninterpreting slide decks,\nextracting data from PDFs and tables,\nunderstanding UI screenshots from trading or analytics tools.\n\n\n\n\nMany providers now offer a mode that:\n\nspends more compute to deliberate,\nperforms better on multi-step tasks,\nis slower and more expensive.\n\nOpenAI’s GPT‑5.2 “Auto” can switch between Instant and Thinking; the UI can show a “slimmed-down” view of chain-of-thought, with an “Answer now” option.[^openai-gpt52-chatgpt]\n\n\n\nA model with tool access can:\n\nbrowse the web (and cite sources),\nuse a Python environment for calculations,\nanalyze files,\ngenerate spreadsheets / slide decks,\ncall external tools through connectors or “actions.”\n\nWithout tools, models are limited to:\n\ntheir training data,\nand whatever you provide in the prompt.\n\n\n\n\n“Deep research” typically means an agentic workflow:\n\nit searches,\ncollects sources,\nsynthesizes,\nand returns citations and an organized report.[^openai-deep-research]\n\nThis is usually not a separate “brain”; it’s an agent layer on top of a strong model + tools.\n\n\n\nCoding assistants aren’t only for programmers. Even if you don’t write software, they can:\n\ntranslate between Stata/R/Python,\nwrite reproducible scripts,\ngenerate data cleaning code,\nand explain unfamiliar code you inherited.\n\nOpenAI’s Codex ecosystem is one example (web/CLI/IDE integrations).[^openai-codex]"
  },
  {
    "objectID": "fundamentals/ecosystem.html",
    "href": "fundamentals/ecosystem.html",
    "title": "The GenAI Ecosystem",
    "section": "",
    "text": "When people say “AI,” or “GenAI,” they often mean “ChatGPT” or a similar chat interface. It’s more useful to think of GenAI in layers:\n\nModels -&gt; the “brains”:\n\nGPT‑5.2, Claude Opus 4.5, Gemini 3.0 Pro, Grok 4.1, etc.\n\nThese models are frequently referred to as LLMs (large language models). This is somewhat of a misnomer these days since the latest iterations of these models can handle more than just language (text) as an input. They can also process audio, image, and video inputs.\n\n\n\nTools -&gt; capabilities around the model:\n\nweb search\nPython interpreter\nfile analysis\nspreadsheet/slides generation\nconnectors to other software/platforms like Outlook, Gmail, Dropbox, Google Drive, GitHub, etc.\n\nProducts (interfaces):\n\nWeb: ChatGPT, Claude, Gemini, Grok\nCoding agents: Codex, Claude Code, Gemini Code Assist, GitHub Copilot\nApps: Perplexity, Replit, Cursor, NotebookLM\n\nMany of these products use agents in the background (workflows orchestrated by a model)\n\nThe model plans steps, uses tools, analyzes the output of those tools, and iterates until it produces the requested output\n\n\n\n\n\n\n\nImage generated with Nano Banana Pro"
  },
  {
    "objectID": "fundamentals/ecosystem.html#framing-what-i-mean-by-genai",
    "href": "fundamentals/ecosystem.html#framing-what-i-mean-by-genai",
    "title": "The GenAI Ecosystem",
    "section": "",
    "text": "When people say “AI,” or “GenAI,” they often mean “ChatGPT” or a similar chat interface. It’s more useful to think of GenAI in layers:\n\nModels -&gt; the “brains”:\n\nGPT‑5.2, Claude Opus 4.5, Gemini 3.0 Pro, Grok 4.1, etc.\n\nThese models are frequently referred to as LLMs (large language models). This is somewhat of a misnomer these days since the latest iterations of these models can handle more than just language (text) as an input. They can also process audio, image, and video inputs.\n\n\n\nTools -&gt; capabilities around the model:\n\nweb search\nPython interpreter\nfile analysis\nspreadsheet/slides generation\nconnectors to other software/platforms like Outlook, Gmail, Dropbox, Google Drive, GitHub, etc.\n\nProducts (interfaces):\n\nWeb: ChatGPT, Claude, Gemini, Grok\nCoding agents: Codex, Claude Code, Gemini Code Assist, GitHub Copilot\nApps: Perplexity, Replit, Cursor, NotebookLM\n\nMany of these products use agents in the background (workflows orchestrated by a model)\n\nThe model plans steps, uses tools, analyzes the output of those tools, and iterates until it produces the requested output\n\n\n\n\n\n\n\nImage generated with Nano Banana Pro"
  },
  {
    "objectID": "fundamentals/ecosystem.html#why-the-genai-as-a-stack-framing-matters",
    "href": "fundamentals/ecosystem.html#why-the-genai-as-a-stack-framing-matters",
    "title": "The GenAI Ecosystem",
    "section": "2 Why the “GenAI as a stack” framing matters",
    "text": "2 Why the “GenAI as a stack” framing matters\nIt reminds us that:\n\nJumps in capability are not just about better models, but better models + better tools + better agentic workflows.\nDifferent products may be better at different tasks (sometimes in a way that is not necessarily related to the models they use underneath)\n\nFor example, Claude (product) may be better than ChatGPT (product) at generating Excel sheets because of better integration with Microsoft Office (tool), not because Claude Opus 4.5 (model) is better than GPT 5.2 (model)\n\nYou should not be judging the current capabilities of “GenAI” based on your experiences with a single product (ChatGPT for most people)"
  },
  {
    "objectID": "fundamentals/index.html",
    "href": "fundamentals/index.html",
    "title": "Fundamentals of GenAI",
    "section": "",
    "text": "This section covers the foundational concepts you need to understand how generative AI works and how to use it effectively."
  },
  {
    "objectID": "fundamentals/index.html#introduction",
    "href": "fundamentals/index.html#introduction",
    "title": "Fundamentals of GenAI",
    "section": "",
    "text": "This section covers the foundational concepts you need to understand how generative AI works and how to use it effectively."
  },
  {
    "objectID": "fundamentals/index.html#topics",
    "href": "fundamentals/index.html#topics",
    "title": "Fundamentals of GenAI",
    "section": "2 Topics",
    "text": "2 Topics\n\n2.1 How LLMs Work\nUnderstand the core mechanics behind Large Language Models:\n\nTransformer architecture basics\nTraining and fine-tuning processes\nTokens and tokenization\nContext windows and attention\n\n\n\n2.2 Key GenAI Capabilities\nExplore what modern GenAI systems can do:\n\nText generation and summarization\nCode generation and assistance\nAnalysis and reasoning\nCreative applications\nMultimodal capabilities\n\n\n\n2.3 Choosing the Right Tool\nLearn to evaluate and select appropriate tools:\n\nMatching capabilities to use cases\nCost considerations\nPrivacy and security factors\nIntegration requirements"
  },
  {
    "objectID": "fundamentals/index.html#why-fundamentals-matter",
    "href": "fundamentals/index.html#why-fundamentals-matter",
    "title": "Fundamentals of GenAI",
    "section": "3 Why Fundamentals Matter",
    "text": "3 Why Fundamentals Matter\n\n\n\n\n\n\nBuilding Strong Foundations\n\n\n\nUnderstanding how these systems work — even at a high level — enables you to:\n\nWrite better prompts\nAnticipate limitations\nTroubleshoot unexpected outputs\nMake informed tool choices"
  },
  {
    "objectID": "fundamentals/index.html#recommended-path",
    "href": "fundamentals/index.html#recommended-path",
    "title": "Fundamentals of GenAI",
    "section": "4 Recommended Path",
    "text": "4 Recommended Path\n\nStart with How LLMs Work to build foundational understanding\nMove to Key Capabilities to see what’s possible\nFinish with Choosing the Right Tool to apply your knowledge\n\nEach section builds on the previous one, so we recommend following this order."
  },
  {
    "objectID": "fundamentals/choosing-tools.html",
    "href": "fundamentals/choosing-tools.html",
    "title": "Choosing the Right Tool",
    "section": "",
    "text": "With dozens of GenAI tools available, selecting the right one for your needs can be overwhelming. This guide provides a framework for making informed choices."
  },
  {
    "objectID": "fundamentals/choosing-tools.html#introduction",
    "href": "fundamentals/choosing-tools.html#introduction",
    "title": "Choosing the Right Tool",
    "section": "",
    "text": "With dozens of GenAI tools available, selecting the right one for your needs can be overwhelming. This guide provides a framework for making informed choices."
  },
  {
    "objectID": "fundamentals/choosing-tools.html#decision-framework",
    "href": "fundamentals/choosing-tools.html#decision-framework",
    "title": "Choosing the Right Tool",
    "section": "2 Decision Framework",
    "text": "2 Decision Framework\n\n2.1 1. Define Your Use Case\nStart by clearly identifying what you need:\n\nTask type: Writing, coding, analysis, research?\nInput/output: Text only, or images/files too?\nFrequency: One-off task or ongoing usage?\nIntegration: Standalone or part of a workflow?\n\n\n\n2.2 2. Evaluate Key Factors\n\n2.2.1 Capability Match\n\n\n\nUse Case\nRecommended Tools\n\n\n\n\nGeneral writing\nChatGPT, Claude, Gemini\n\n\nCode development\nGitHub Copilot, Cursor, Claude\n\n\nResearch & search\nPerplexity, Gemini\n\n\nImage generation\nMidjourney, DALL-E, Stable Diffusion\n\n\nDocument analysis\nClaude (long context), Gemini\n\n\n\n\n\n2.2.2 Cost Considerations\n\n\n\n\n\n\nPricing Models\n\n\n\n\nFree tiers: Limited usage, good for exploration\nSubscriptions: $20/month typical for premium access\nAPI pricing: Pay per token, scales with usage\nEnterprise: Custom pricing with additional features\n\n\n\n\n\n2.2.3 Privacy & Security\nConsider data handling requirements:\n\nSensitive data: May require local/on-premise solutions\nCompliance: Check vendor certifications (SOC 2, etc.)\nData retention: Understand how inputs are stored/used\nTraining opt-out: Some providers allow opting out of training\n\n\n\n\n2.3 3. Practical Considerations\n\n2.3.1 Ease of Use\n\nWeb interface vs. API vs. integrated tool\nLearning curve and documentation quality\nTeam collaboration features\n\n\n\n2.3.2 Reliability\n\nUptime and availability\nRate limits and quotas\nResponse consistency\n\n\n\n2.3.3 Ecosystem\n\nPlugins and extensions\nIntegration with existing tools\nCommunity and support"
  },
  {
    "objectID": "fundamentals/choosing-tools.html#tool-categories",
    "href": "fundamentals/choosing-tools.html#tool-categories",
    "title": "Choosing the Right Tool",
    "section": "3 Tool Categories",
    "text": "3 Tool Categories\n\n3.1 Conversational Assistants\nBest for: General tasks, brainstorming, Q&A\n\nChatGPT (OpenAI)\nClaude (Anthropic)\nGemini (Google)\n\n\n\n3.2 Code Assistants\nBest for: Development workflows\n\nGitHub Copilot — IDE integration\nCursor — AI-native editor\nCodeium — Free alternative\n\n\n\n3.3 Search & Research\nBest for: Information retrieval, citations\n\nPerplexity — AI search with sources\nGemini — Google integration\nConsensus — Academic research\n\n\n\n3.4 Specialized Tools\nBest for: Specific domains\n\nGrammarly — Writing assistance\nNotion AI — Note-taking and docs\nJasper — Marketing content"
  },
  {
    "objectID": "fundamentals/choosing-tools.html#making-the-choice",
    "href": "fundamentals/choosing-tools.html#making-the-choice",
    "title": "Choosing the Right Tool",
    "section": "4 Making the Choice",
    "text": "4 Making the Choice\n\n\n\n\n\n\nRecommendation\n\n\n\nStart with a general-purpose tool (ChatGPT or Claude) to understand your needs, then specialize if necessary. Most users find 2-3 tools cover their needs.\n\n\n\n4.1 Quick Selection Guide\nNeed general assistance? → ChatGPT or Claude\nNeed to search/research? → Perplexity\nNeed code help in IDE? → GitHub Copilot or Cursor\nNeed image generation? → Midjourney or DALL-E\nNeed document analysis? → Claude (long context)\nNeed privacy/local? → Llama-based solutions"
  },
  {
    "objectID": "fundamentals/choosing-tools.html#evaluation-checklist",
    "href": "fundamentals/choosing-tools.html#evaluation-checklist",
    "title": "Choosing the Right Tool",
    "section": "5 Evaluation Checklist",
    "text": "5 Evaluation Checklist\nBefore committing to a tool:\n\nTest with your actual use cases\nReview pricing for expected usage\nCheck data handling policies\nEvaluate integration options\nConsider team/organization needs\nPlan for potential switching costs"
  },
  {
    "objectID": "fundamentals/how-llms-work.html",
    "href": "fundamentals/how-llms-work.html",
    "title": "How GenAI Models Work",
    "section": "",
    "text": "Here’s the most important thing to understand: a large language model is just a file full of numbers.\nWhen companies like OpenAI, Anthropic, or Google train a model, they’re creating a very large file—hundreds of gigabytes for frontier models—that contains billions of numerical parameters. These parameters encode patterns learned from reading enormous amounts of text.\nWhat do we mean by “patterns” in text? Some of these are grammar-related patterns, but they need not be. Here’s an intuitive example: if I asked you to finishe the sentence: “I think therefore I …”, most of you would say “am”. You did that because overwhelmingly, whenever you’ve encountered the phrase “I think therefore I”, it was followed by “am”.\nThat’s essentially what the model “knows”—statistical patterns about how language works and what tends to follow what.\n\n\nThe training process happens in stages:\nPre-training: The model reads massive amounts of text from the internet, books, code repositories, academic papers—essentially a substantial portion of human written output. During this phase, it learns to predict “what word comes next?” billions of times. The parameters adjust to get better at prediction. This takes months and costs tens to hundreds of millions of dollars in compute.\nPost-training (Fine-tuning): The base model is then adjusted using: - Supervised fine-tuning (SFT): Humans write example conversations showing how the model should respond - Reinforcement learning from human feedback (RLHF): Humans rate model outputs, and the model learns to generate outputs that get higher ratings - Constitutional AI (CAI): Used by Anthropic, where the model learns to critique and revise its own outputs based on principles\nContinuous refinement: Models are updated regularly to improve performance, fix issues, and add capabilities.\nKey terms you might hear: “transformer architecture” (the mathematical structure these models use), “attention mechanism” (how the model decides what parts of the input to focus on), “parameters” or “weights” (the numbers in the file)."
  },
  {
    "objectID": "fundamentals/how-llms-work.html#the-big-picture",
    "href": "fundamentals/how-llms-work.html#the-big-picture",
    "title": "How GenAI Models Work",
    "section": "",
    "text": "Large Language Models (LLMs) are neural networks trained to predict the next token in a sequence. Despite this simple objective, this training process produces systems with remarkable capabilities.\n\n\nWhen you type into ChatGPT (or an API), the system does roughly this:\n\nYour text is converted into tokens (numbers).\nTokens are turned into vectors (“embeddings”).\nThe model runs a forward pass (a lot of matrix multiplication / attention).\nIt produces probabilities for the next token.\nA decoding method picks the next token (sampling / temperature / etc.).\nRepeat until it hits a stop condition or an output limit.\n\nKey implication:\nThe model is not retrieving a “stored answer.” It is generating a continuation that fits the prompt and its training patterns."
  },
  {
    "objectID": "fundamentals/how-llms-work.html#key-concepts",
    "href": "fundamentals/how-llms-work.html#key-concepts",
    "title": "How GenAI Models Work",
    "section": "3 Key Concepts",
    "text": "3 Key Concepts\n\n3.1 Tokens\nLLMs don’t process text character by character — they use tokens.\n\nA token might be a word, part of a word, or punctuation\n“Understanding” might be split into “Under” + “standing”\nMost models use ~50,000 different tokens\nToken count affects cost and context limits\n\n\n\n\n\n\n\nRule of Thumb\n\n\n\nIn English, 1 token ≈ 4 characters or ¾ of a word. A 1,000 word document is roughly 1,300-1,500 tokens.\n\n\n\n\n3.2 The Transformer Architecture\nThe transformer is the neural network architecture powering modern LLMs. Key components:\n\nEmbeddings — Convert tokens to numerical vectors\nAttention — Allow tokens to “look at” other tokens\nFeed-forward layers — Process information\nOutput layer — Predict next token probabilities\n\n\n\n3.3 Attention: The Key Innovation\nAttention mechanisms allow the model to focus on relevant parts of the input:\n\"The cat sat on the mat because it was tired\"\n                                ↑\n                    What does \"it\" refer to?\nThe attention mechanism helps the model understand that “it” refers to “cat” by learning patterns from training data.\n\n\n3.4 What does “training” a model actually mean?\n\nPre-training (self-supervised)\n\nThe model reads huge corpora and learns to predict the next token.\nOutcome: broad language competence + lots of embedded world knowledge.\n\nMid-training / continued training (optional, but common)\n\nAdditional training on domain data, long-context data, code, or multimodal data.\nOutcome: “specialization,” better long-document handling, better domain patterns.\n\nPost-training (instruction following + alignment)\n\nSFT (supervised fine-tuning on instruction data),\nRLHF / RLAIF (reinforcement learning from human/AI feedback),\nDPO (direct preference optimization),\nsafety tuning and refusal training.\n\n\nOutcome: the model becomes better at following user intent, formatting outputs, and refusing unsafe requests."
  },
  {
    "objectID": "fundamentals/how-llms-work.html#context-windows",
    "href": "fundamentals/how-llms-work.html#context-windows",
    "title": "How GenAI Models Work",
    "section": "4 Context windows",
    "text": "4 Context windows\n\n4.1 What is a context window?\nThe context window is the maximum amount of text (and other inputs) the model can consider at once:\n(system instructions + your prompt + chat history + retrieved snippets + tool outputs + file excerpts) + the model’s output.\nIf the total exceeds the limit:\n\nthe system must drop, summarize, or “compact” something,\nor it returns an error (depending on provider).\n\n\n\n4.2 What providers may include automatically (even if you don’t see it)\nMany modern assistants can add extra context such as:\n\nsystem safety instructions,\nyour custom instructions,\nproject instructions,\n“memory” items (facts it saved about your preferences),\nsnippets retrieved from uploaded files or connected tools.\n\nThis is why two people can ask the “same prompt” and get slightly different results.\n\n\n4.3 Uploading files: why “I uploaded it” ≠ “the model read it”\nIn most systems, uploading a file does not mean the entire file is placed into the context window verbatim.\nA common approach is retrieval:\n\nthe file is chunked,\nthe system builds embeddings (a searchable representation),\nand only relevant chunks are pulled into the context window when needed.\n\nOpenAI explicitly describes this chunking/embedding behavior for “Knowledge” files in custom GPTs.[^openai-knowledge-files]\nFaculty implication:\nTo get reliable file-based answers, you often need to ask for:\n\ncitations / quotes with page numbers,\nexplicit references to the provided document,\nand “show your work” audits (e.g., “quote the exact line you used”).\n\n\n\n4.4 What happens near the limit\nDifferent providers handle this differently:\n\nSome UIs summarize older messages.\nSome drop the earliest conversation turns (“truncation”).\nSome run a compaction step to preserve key details.\n\nOpenAI notes a /compact approach (in its ecosystem) for extending effective context windows in tool-heavy workflows.[^openai-gpt52] Anthropic documents that their API returns errors if input + output exceeds the context window rather than silently truncating.[^anthropic-context]\n\n\n4.5 Output limits\nEven with a huge input window, models have output caps. When you ask for “write 30 pages,” you usually get:\n\na truncated response,\nor a refusal,\nor “here is an outline; ask me to expand section by section.”\n\nFaculty-friendly move:\nFor long outputs, ask for:\n\noutline, 2) draft section 1, 3) draft section 2…\n\nThis yields better control and fewer errors."
  },
  {
    "objectID": "fundamentals/how-llms-work.html#the-model-as-a-file",
    "href": "fundamentals/how-llms-work.html#the-model-as-a-file",
    "title": "How GenAI Models Work",
    "section": "",
    "text": "Here’s the most important thing to understand: a large language model is just a file full of numbers.\nWhen companies like OpenAI, Anthropic, or Google train a model, they’re creating a very large file—hundreds of gigabytes for frontier models—that contains billions of numerical parameters. These parameters encode patterns learned from reading enormous amounts of text.\nWhat do we mean by “patterns” in text? Some of these are grammar-related patterns, but they need not be. Here’s an intuitive example: if I asked you to finishe the sentence: “I think therefore I …”, most of you would say “am”. You did that because overwhelmingly, whenever you’ve encountered the phrase “I think therefore I”, it was followed by “am”.\nThat’s essentially what the model “knows”—statistical patterns about how language works and what tends to follow what.\n\n\nThe training process happens in stages:\nPre-training: The model reads massive amounts of text from the internet, books, code repositories, academic papers—essentially a substantial portion of human written output. During this phase, it learns to predict “what word comes next?” billions of times. The parameters adjust to get better at prediction. This takes months and costs tens to hundreds of millions of dollars in compute.\nPost-training (Fine-tuning): The base model is then adjusted using: - Supervised fine-tuning (SFT): Humans write example conversations showing how the model should respond - Reinforcement learning from human feedback (RLHF): Humans rate model outputs, and the model learns to generate outputs that get higher ratings - Constitutional AI (CAI): Used by Anthropic, where the model learns to critique and revise its own outputs based on principles\nContinuous refinement: Models are updated regularly to improve performance, fix issues, and add capabilities.\nKey terms you might hear: “transformer architecture” (the mathematical structure these models use), “attention mechanism” (how the model decides what parts of the input to focus on), “parameters” or “weights” (the numbers in the file)."
  },
  {
    "objectID": "fundamentals/how-llms-work.html#what-happens-when-you-prompt",
    "href": "fundamentals/how-llms-work.html#what-happens-when-you-prompt",
    "title": "How GenAI Models Work",
    "section": "2 What Happens When You Prompt",
    "text": "2 What Happens When You Prompt\nWhen you type a question into ChatGPT or Claude, here’s what actually happens:\n\nTokenization: Your text is converted into numbers. The word “investment” might become token 7342. “Portfolio” might be 4521. Each model has its own vocabulary of tokens.\nContext assembly: Your prompt is combined with any previous messages in the conversation, plus a “system prompt” (instructions the model provider includes automatically—more on this later).\nForward pass: The tokenized input goes through the model’s neural network. Each layer does mathematical operations—essentially matrix multiplications—transforming the input through the billions of parameters.\nOutput generation: The model produces a probability distribution over all possible next tokens. It samples from this distribution (with some randomness controlled by “temperature”), adds that token to the sequence, and repeats until it decides to stop.\nDetokenization: The output tokens are converted back to human-readable text.\n\nThe key insight: the model is doing sophisticated pattern matching and transformation, not reasoning from first principles. It’s incredibly good at producing text that looks like text it saw during training. But it has no real understanding in the way humans understand—it can’t verify its outputs against reality.\nThis is why AI systems can be confidently wrong. They produce plausible-sounding text, but that plausibility comes from statistical patterns, not from checking facts."
  }
]