---
title: "Key GenAI Capabilities"
---

## Key ways models differ (what to pay attention to)

### Context window size

- Bigger windows help with long syllabi, papers, transcripts, cases, and multi-file projects.
- But bigger windows **do not guarantee** accurate long-document reasoning.

Examples of publicly stated context sizes (as of late 2025):

- OpenAI’s GPT‑5.2 Pro API model: **400k context window**, **128k max output** (API docs).[^openai-gpt52pro-api]  
- ChatGPT UI (GPT‑5.2): context varies by tier/model (e.g., “Thinking” has a much larger window than “Instant”).[^openai-gpt52-chatgpt]  
- Google Gemini 2.5 Pro: announced **1M token** context.[^google-gemini-25pro]  
- Anthropic Claude long-context tiers include models with up to **1M tokens**.[^anthropic-context]

### Multimodality (text + image + audio + video)

Ask:

- Can it read charts, tables, and screenshots?
- Can it *generate* images or just analyze them?
- Is multimodality native (one model) or stitched (separate encoders + LLM)?

For finance, multimodality matters for:

- reading charts in papers,
- interpreting slide decks,
- extracting data from PDFs and tables,
- understanding UI screenshots from trading or analytics tools.

### “Thinking” / reasoning mode vs “instant” mode

Many providers now offer a mode that:

- spends more compute to deliberate,
- performs better on multi-step tasks,
- is slower and more expensive.

OpenAI’s GPT‑5.2 “Auto” can switch between Instant and Thinking; the UI can show a “slimmed-down” view of chain-of-thought, with an “Answer now” option.[^openai-gpt52-chatgpt]

### Tool access (this matters more than people realize)

A model with tool access can:

- browse the web (and cite sources),
- use a Python environment for calculations,
- analyze files,
- generate spreadsheets / slide decks,
- call external tools through connectors or “actions.”

Without tools, models are limited to:

- their training data,
- and whatever you provide in the prompt.

### Deep research vs “normal chat”

“Deep research” typically means an **agentic workflow**:

- it searches,
- collects sources,
- synthesizes,
- and returns citations and an organized report.[^openai-deep-research]

This is usually not a separate “brain”; it’s an **agent layer** on top of a strong model + tools.

### Coding agents and IDE copilots

Coding assistants aren’t only for programmers. Even if you don’t write software, they can:

- translate between Stata/R/Python,
- write reproducible scripts,
- generate data cleaning code,
- and explain unfamiliar code you inherited.

OpenAI’s Codex ecosystem is one example (web/CLI/IDE integrations).[^openai-codex]
