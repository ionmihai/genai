---
title: "How GenAI Models Work"
subtitle: A non-technical introduction
---

## The Model as a File

Here's the most important thing to understand: **a large language model is just a file full of numbers.**

When companies like OpenAI, Anthropic, or Google train a model, they're creating a very large file—hundreds of gigabytes for frontier models—that contains billions of numerical parameters. These parameters encode patterns learned from reading enormous amounts of text.

What do we mean by "patterns" in text? Some of these are grammar-related patterns, but they need not be. Here's an intuitive example: if I asked you to finishe the sentence: "I think therefore I ... ", most of you would say "am". You did that because overwhelmingly, whenever you've encountered the phrase "I think therefore I", it was followed by "am". 

That's essentially what the model "knows"—statistical patterns about how language works and what tends to follow what.

### How the Numbers Are Obtained

The training process happens in stages:

**Pre-training:** The model reads massive amounts of text from the internet, books, code repositories, academic papers—essentially a substantial portion of human written output. During this phase, it learns to predict "what word comes next?" billions of times. The parameters adjust to get better at prediction. This takes months and costs tens to hundreds of millions of dollars in compute.

**Post-training (Fine-tuning):** The base model is then adjusted using:

- **Supervised fine-tuning (SFT):** Humans write example conversations showing how the model should respond
- **Reinforcement learning from human feedback (RLHF):** Humans rate model outputs, and the model learns to generate outputs that get higher ratings
- **Constitutional AI (CAI):** Used by Anthropic, where the model learns to critique and revise its own outputs based on principles

**Continuous refinement:** Models are updated regularly to improve performance, fix issues, and add capabilities.

Key terms you might hear: "transformer architecture" (the mathematical structure these models use), "attention mechanism" (how the model decides what parts of the input to focus on), "parameters" or "weights" (the numbers in the file).

---

## What Happens When You Prompt

When you type a question into ChatGPT or Claude, here's what actually happens:

1. **Tokenization:** Your text is converted into numbers. The word "investment" might become token 7342. "Portfolio" might be 4521. Each model has its own vocabulary of tokens.

2. **Context assembly:** Your prompt is combined with any previous messages in the conversation, plus a "system prompt" (instructions the model provider includes automatically—more on this later).

3. **Forward pass:** The tokenized input goes through the model's neural network. Each layer does mathematical operations—essentially matrix multiplications—transforming the input through the billions of parameters.

4. **Output generation:** The model produces a probability distribution over all possible next tokens. It samples from this distribution (with some randomness controlled by "temperature"), adds that token to the sequence, and repeats until it decides to stop.

5. **Detokenization:** The output tokens are converted back to human-readable text.

The key insight: **the model is doing sophisticated pattern matching and transformation, not reasoning from first principles.** It's incredibly good at producing text that looks like text it saw during training. But it has no real understanding in the way humans understand—it can't verify its outputs against reality (without the use of tools).

This is why AI systems can be confidently wrong. They produce plausible-sounding text, but that plausibility comes from statistical patterns, not from checking facts.

---

## Context windows

### What is a context window?

The **context window** is the maximum amount of text (and other inputs) the model can consider at once:  
**(system instructions + your prompt + chat history + retrieved snippets + tool outputs + file excerpts) + the model’s output.**

If the total exceeds the limit:

- the system must drop, summarize, or “compact” something,
- or it returns an error (depending on provider).

### What providers may include automatically (even if you don’t see it)

Many modern assistants can add extra context such as:

- system safety instructions,
- your custom instructions,
- project instructions,
- “memory” items (facts it saved about your preferences),
- snippets retrieved from uploaded files or connected tools.

This is why two people can ask the “same prompt” and get slightly different results.

### Uploading files: why “I uploaded it” ≠ “the model read it”

In most systems, uploading a file does **not** mean the entire file is placed into the context window verbatim.

A common approach is retrieval:

- the file is chunked,
- the system builds embeddings (a searchable representation),
- and only relevant chunks are pulled into the context window when needed.

OpenAI explicitly describes this chunking/embedding behavior for “Knowledge” files in custom GPTs.

**Faculty implication:**  
To get reliable file-based answers, you often need to ask for:

- citations / quotes with page numbers,
- explicit references to the provided document,
- and “show your work” audits (e.g., “quote the exact line you used”).

### What happens near the limit
Different providers handle this differently:

- Some UIs summarize older messages.
- Some drop the earliest conversation turns (“truncation”).
- Some run a compaction step to preserve key details.

OpenAI notes a `/compact` approach (in its ecosystem) for extending effective context windows in tool-heavy workflows. Anthropic documents that their API returns errors if input + output exceeds the context window rather than silently truncating.

### Output limits
Even with a huge input window, models have **output caps**. When you ask for “write 30 pages,” you usually get:

- a truncated response,
- or a refusal,
- or “here is an outline; ask me to expand section by section.”

**Recommendation:**  
For long outputs, ask for 1) outline, 2) draft section 1, 3) draft section 2…  

This yields better control and fewer errors.
